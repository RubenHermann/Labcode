---
title: "Uniform vs Hierarchical Study design"
author: "AG Pantel"
date: "`r Sys.Date()`"
output: html_document
knit: (function(input_file, encoding) {
    rmarkdown::render(input_file,
      encoding=encoding,
      output_file= 'index.html')})
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(pander)
library(MASS)
library(Hmsc)
library(RColorBrewer)
library(lme4)
library(mixedup)
```

## Creating a simple code to learn about mixed models

First I am creating a simple plot to show the uniform study design

```{r}
x_cord <- 1:10
y_cord <- 1:10
d <- expand.grid(x_cord,y_cord)
plot(d,pch=19,col="black",cex=2,xlab="x-position (longitude)",ylab="y-position (latitude)"
     ,main="Uniform residual variance")

```

This is the plot to show the hierarchical study design

```{r}

patches <-c("black","maroon4","midnightblue","firebrick1","darkorchid4",
            "coral3","khaki1","gray47","mediumspringgreen","cyan3")

plot(d,pch=19,col=patches,cex=2,xlab="x-position (longitude)",ylab="y-position (latitude)"
     ,main="Hierarchical study design")
```

These are the data for the uniform data design --> epsilon is for all sample units from the
same distribution $\varepsilon \sim N(0,1)$

```{r}
n = 100 #sampling sides
set.seed(7) 
x = rnorm(n) 
sample.id = 1:n
beta1 = 0
beta2 = 1
sigma = 1
L = beta1 + beta2*x
y = L + rnorm(n, sd = sigma)
data <- data.frame(sampling_unit=sample.id,covariate=x,counts=y,predictor=L)
plot(x,y,xlab="Covariate",ylab="Counts"
     ,main="Uniform design")
```

These are the data for the hierarchical data design --> epsilon is part of two distributions
1. the same error distributions for all sampling units as above $\varepsilon \sim N(0,1)$
2. the added variance of the plot-level effects $a_p \sim N(0,\sigma^2_P)$
as such we have $\epsilon_i = \varepsilon_i + a_{p(i)}$

```{r}
n = 100
L = beta1 + beta2*x
np = 10
plot.id = c(rep(1:10,10))
sigma.plot = 1
ap = rnorm(np, sd = sigma.plot)
a = ap[plot.id]
y = L + a + rnorm(n, sd = sigma)
plot.id = as.factor(plot.id)
data2 <- data.frame(sampling_unit=sample.id,plots=plot.id,covariate=x,counts=y,predictor=L,plot_effect=a)
plot(x,y,col = plot.id, las = 1,xlab="Covariate",ylab="Counts"
     ,main="Hierarchical study design")
```

## Code to better understand non-heirarchical and heirarchical errors

I model here the abundance / population size (`y`) of a single species in the uniform landscape pictured above, at each site `i`. The average population size is $\alpha = \beta_1 = 450$, but also varies depending on the local site's value of the environmental covariate $x_i$, as well as unstructured (non-hierarchical) error (unexplained variation in population size) $\epsilon_i$. I include an impact of $\beta = \beta_2 = 1.23$ - for each unit change in *x*, there is a corresponding increase by 1.23 of *y*.

```{r}
n <- 100
x1 <- rep(1,n)
x2 <- x
beta1 <- 450
beta2 <- 1.23
L <- beta1*x1 + beta2*x2
```

Currently, the population size values follow perfectly the expectation given by the impact of *x* on *y*:

```{r}
plot(x,L,main="Impact of environment x on population size Y at site i",ylab="yi")
```

However, each sampling site has some unexplained error, or some unexplained deviation from the average population size after taking the environmental covariate *x* into account. We still hypothesize / state that the population size values are drawn from a single, shared distribution, with a shared center $L_i$ and a shared variance $\sigma^2$. The response variable cannot be expected be fully predicted by the explanatory variable, and there will be residuals. The residual variation is assumed to be normally distributed, as $\epsilon_i \sim N(0,\sigma^2)$, where $\sigma$ is the standard deviation.

```{r,out.width="50%"}
sigma <- 0.25
e <- rnorm(n,0,sigma)
y <- L + e
hist(e)
plot(x,y,main="Impact of environment x on population size Y at site i",ylab="yi")
```

We can use R's `lm` to fit a linear model to this data - we imagine we are researchers collecting data, and we do not know the impact of environmental covariate *x* on population size *y*.

```{r}
mod_lm <- lm(y ~ x2)
summary(mod_lm)
```

And we can see that fitting a linear model does a good job at estimating the parameters in our model $\alpha = \beta_1$, $\beta = \beta_2$, and $\epsilon$:

```{r}
pander::pander(summary(mod_lm))
pander::pander(anova(mod_lm))
```

The estimate for the intercept $\alpha = \beta_1$ is `r coef(summary(mod_lm))[1,1]` ± `r coef(summary(mod_lm))[1,2]`, the estimate for $\beta = \beta_2$ is `r coef(summary(mod_lm))[2,1]` ± `r coef(summary(mod_lm))[2,2]`, and the estimate for $\sigma$ is `r summary(mod_lm)$sigma`.

We can also consider this using HMSC:

```{r}
## Will insert code here to run the analysis above using HMSC
```

Next, we can consider there is spatial structure in the residuals - as discussed above, we now consider a hierarchical study design where multiple sampling units have been surveyed within a higher hierarchical level of plot. We expect that the data points from within the same plot are more similar than the data points originating from different plots, and therefore that their residuals are positively correlated within plots.

In the 1st example:

$$ y_i = \alpha + \beta x_i + \epsilon_i $$

Which can also be written as:

$$ y_i = \sum^{n_c}_{k=1}x_ik \beta_k + \epsilon_i $$
if $\alpha = \beta_1$, $x_{i1} = 1$ for all sampling units *i*, and $\beta = \beta_2$

A third way to write the equation is:

$$ y_i \sim N(L_i,\sigma^2) $$
$$ L_i = \sum^{n_c}_{k=1} x_{ik} \beta_k $$

In the 2nd example, a plot-level random effect is entered that introduces dependency structure of errors. Data points originating from the same plot are more similar than the data points originating from different plots, and thus residuals within the same plot are expected to be positively correlated.

Ruben implemented this using:

$$ y_i = L_i + a_{p(i)} + \epsilon_i $$
$$ a_{p(i)} \sim N(0,\sigma^2_p) $$
$$ \epsilon_i \sim N(0,\sigma^2) $$
For Ruben's example, the within-plot variance for each of the 10 plots $\sigma_p$ = [`r ap`]. We can literally see in his code that he followed this equation:

```{r, eval=FALSE}
n = 100
L = beta1 + beta2*x
np = 10
plot.id = c(rep(1:10,10))
sigma.plot = 1
ap = rnorm(np, sd = sigma.plot)
a = ap[plot.id]
y = L + a + rnorm(n, sd = sigma) # This corresponds to the yi formula above
```

Our JDSM CHapter 5 text tells us another way of writing this equation (5.7 in the text), using the *multivariate normal distribution* for descrobing the distribution of response variables $y_i$ for all sampling units *i* - we denote by $\mathbf{y}$ the vector of length *n* (number of sampling units) with all of the values of $y_i$, we denote by $\mathbf{L}$ the vector of all linear predictors $L_i$, and by $\mathbf{\epsilon}$ the vector of all residuals $\epsilon_i$. We can then rewrite the equation as:

$$ \mathbf{y} \sim \mathbf{L} + \epsilon_i$$
$$ \epsilon_i \sim N(\mathbf{0},\mathbf{\Sigma}) $$

Where $N(\mathbf{\mu},\mathbf{\Sigma})$ stands for the multivariate normal distribution with mean $\mathbf{\mu}$ and variance-covariance matrix $\mathbf{\Sigma}$. In this equation above, the vector $\mathbf{\mu}$ is set to 0 because the expectation of each $\epsilon_i$ value is 0. The diagonal elements of the variance-covariance matrix $\mathbf{\Sigma}$ model the variances, and thus are set to $\Sigma_{ii} = \sigma^2_p + \sigma^2$. The off-diagonal elements of the variance-covariance matrix $\mathbf{\Sigma}$ model the covariances, and here are set to $\Sigma_{ij} = \sigma^2_p$ if the sampling units *i* and *j* belong to the same plot, and $\Sigma_{ij} = 0$ if the sampling units *i* and *j* belong different plots.

For the example we look at so far, this variance-covariance matrix looks like this:

```{r, eval=FALSE}
# create sample data
Sigma <- matrix(rep(0,10),nrow=10,ncol=10)
diag(Sigma) <- sigma.plot + sigma
Sigma[upper.tri(Sigma)] <- 0
Sigma[lower.tri(Sigma)] <- 0
Sigma <- lqmm::make.positive.definite(Sigma, tol=1e-3)
## this needs to be changed so that the off-diagonals not in the same plot are set to zero ##
## and the command below does not work
var(MASS::mvrnorm(n=1, mu=c(rep(0,10)), Sigma=Sigma)) # I just changed the syntax a little and also put 0 for mu, but I still need to figure out how multivariate normal distribution really functions. So this was a first attempt to do so. 
```


## Code for model with within-plot variance with variance-covariance matrix

Create Model:
```{r out.width="70%"}
set.seed(7) 
n <- 100
x = rnorm(n) 
x1 <- rep(1,n)
x2 <- x
beta1 <- 450
beta2 <- 1.23
L <- beta1*x1 + beta2*x2

p= c(0.3, 0.2, 0.5, 0.4, 0.3, 0.6, 0.4, 0.2, 0.1, 0.9) # correlation for sampling units inside same plots (plot 1-10), proportion of residual variance that can be attributed to the plot level
sigma <- as.numeric(0.25)
sigma.plot= (p*sigma/(-p+1)) 
Sigma.plot=rep(sigma.plot, each=10)

Sigma <- matrix(rep(0,100),nrow=100,ncol=100)

counter=0
for (j in 1:10) {
  for (i in 1:10) {
    Sigma [i+counter,1+counter]= sigma.plot[j]
    Sigma [i+counter,2+counter]= sigma.plot[j]
    Sigma [i+counter,3+counter]= sigma.plot[j]
    Sigma [i+counter,4+counter]= sigma.plot[j]
    Sigma [i+counter,5+counter]= sigma.plot[j]
    Sigma [i+counter,6+counter]= sigma.plot[j]
    Sigma [i+counter,7+counter]= sigma.plot[j]
    Sigma [i+counter,8+counter]= sigma.plot[j]
    Sigma [i+counter,9+counter]= sigma.plot[j]
    Sigma [i+counter,10+counter]= sigma.plot[j]
  } 
  counter=counter+10
}

diag(Sigma) <- Sigma.plot + sigma

Sigma <- lqmm::make.positive.definite(Sigma, tol=1e-3)
E=MASS::mvrnorm(1,mu = c(rep(0,100)), Sigma = Sigma) 

y= L + E 

plot(x,y,main="Impact of environment x + Multivariate Normal Distribution on population size Y at site i",ylab="Y")
lines(x, L, col="black", lwd=2)


```

HMSC and explaining the MCMC + plots
```{r}
#constructing the model
n.plot <- rep(1:10,each=10)
plot.id = as.factor(n.plot)
sample.id = as.factor(1:n)
XData = data.frame(x = x)
Y = as.matrix(y)
studyDesign = data.frame(sample = sample.id, plot = plot.id) 
rL = HmscRandomLevel(units = studyDesign$plot)
m = Hmsc(Y = Y, XData = XData, XFormula = ~x,studyDesign = studyDesign, ranLevels = list("plot" = rL))

#defining parameters for sampleMCMC function
nChains = 2 # how many chains
thin = 5 #  how much thinning to apply = how many steps of the iterations are stored (in this case every 5th step is stored)
samples = 1000 # how many samples to obtain per chain
transient = 500*thin # what length of a transient, when to start storing the results (here at step 2500)
# every 5th sample is stored (thinning) * 1000 samples are obtained (samples) + 2500 samples are discarded at the beginning (transient) = 7500 step chain *2 (nChains)
verbose = 500*thin # how frequently to see the progress of MCMC

m = sampleMcmc(m, thin = thin, samples = samples, transient = transient,nChains = nChains, verbose = verbose)

```
```{r out.width="70%"}
m.post = Hmsc::convertToCodaObject(m) # convert to coda object to extract the posterior distribution

summary(m.post$Beta) # get results for the beta parameter
plot(m.post$Beta) # plot results for the beta parameter
effectiveSize(m.post$Beta) 
gelman.diag(m.post$Beta,multivariate = FALSE)$psrf # potential scale reduction factor 



```
Description of the plots:

The two lines of the plot (black and red) describe the MCMC chains: 

+ They yield identical results - convergence of the Chains
+ they rapidly rise and fall - no autocorrelation
+ They seem to have reached a stationary distribution as first half of recorded iterations looks similar to second half in the plot

Quantitative measure of convergence: 

+ The effective sample size shows how much the consecutive samples are autocorrelated: No autocorrelation -> no direction the samples of the MCMC are going -> They are jumping around a mean which should be the parameter mean
+ The potential scale reduction factor shows how consistent the results between both chains are: Is an estimate of how much narrower the posterior might become with an infinite number of iterations, when (near) 1, the cahins have converged and are similar to each other. -> "A large PSRF indicates that the between-chain variance is substantially greater than the within-chain variance, so that longer simulation is needed. If a PSRF is close to 1, then the associated chains are likely to have converged to one target distribution. A large PSRF (perhaps generally when a PSRF > 1.2) indicates convergence failure, and can indicate the presence of a multimodal marginal posterior distribution in which different chains may have converged to different local modes (see is.multimodal), or the need to update the associated chains longer, because burn-in (see burnin) has yet to be completed." 
[link](https://search.r-project.org/CRAN/refmans/LaplacesDemon/html/Gelman.Diagnostic.html#:~:text=The%20'potential%20scale%20reduction%20factor,number%20of%20iterations%20approaches%20infinity.)


Explanatory power of model:

```{r out.width="70%"}
preds = computePredictedValues(m)
MF = evaluateModelFit(hM = m, predY = preds) 
MF$R2

preds.mean = apply(preds, FUN = mean, MARGIN = 1) 
nres = scale(y-preds.mean)
par(mfrow = c(1,2))
hist(nres)
plot(preds.mean, nres)
abline(a = 0, b = 0)
```
The first plot shows that the residuals are normally distributed, the second plot that the residual variation is homoscedastic.

The R^2 value is a measure of the explanatory power of the model:
\begin{align}
R^{2} = 1 - \frac{SQR}{SQT} = 1 - \frac{(\sum_{i}(y_i - \hat{y}) ^2)}{(\sum_{i}(y_i - \overline{y})^2)}
\end{align}

SQR gets bigger if there is a higher error value (high residual values -> higher values in numerator ->), leading to a smaller R2. 


```{r}
1- (sum((m$Y-preds.mean)^2))/(sum((m$Y-mean(m$Y))^2))
```



## 1A. Linear model, single species

HMSC (Vignette 1) simulate univariate data, which represents population size `n` of a single species sampled at $i$ = 50 sampling units, each of which has a distinct value for an environmental covariate $x_i$. The data is simulated by the standard linear model with normally distributed residuals:

\begin{align}
y_i = \alpha + \beta x_i + \epsilon_i
\end{align}

where $\epsilon_i \sim N(0,\sigma^2)$

This can be alternatively written as:

\begin{align}
y_i = \sum^{n_c}_{k=1} x_{ik} \beta_k + \epsilon_i
\end{align}

Where the number of covariates is $n_c -1$, $\beta_1$ is the intercept term ($\alpha$) and $x_{i1} = 1$. We can also write this equation as:

\begin{align}
y_i \sim N(L_i,\sigma^2)
\end{align}

Where $L_i$ is called the linear predictor:

\begin{align}
L_i = \sum^{n_c}_{k=1} x_{ik}\beta_k
\end{align}

And `n` is the number of data points, `x` is a continuous covariate, `alpha` and `beta` are the true parameters for intercept and slope, `L` is the linear predictor, and `y` is the response variable (population size).

```{r out.width="40%"}
set.seed(1)
n = 50
x = rnorm(n)
alpha = 0
beta = 1
sigma = 1
L = alpha + beta*x
y = L + rnorm(n, sd = sigma)
plot(x, y, las=1)
```
This data is analyzed via HMSC as follows:

```{r out.width="70%",warning=FALSE,message=FALSE,results='hide',fig.keep='all'}
Y = as.matrix(y)
XData = data.frame(x = x)
m = Hmsc(Y = Y, XData = XData, XFormula = ~x)
# MCMC parameters
nChains = 2
thin = 5
samples = 1000
transient = 500*thin
verbose = 500*thin

m = sampleMcmc(m, thin = thin, samples = samples, transient = transient, nChains = 2, verbose = verbose)

# Interpret results
m.post = Hmsc::convertToCodaObject(m)
m.df <- as.data.frame(rbind(m.post$Beta[[1]],m.post$Beta[[2]]))
bayesplot::mcmc_areas(m.df)
summary(m.post$Beta)
plot(m.post$Beta)
preds = computePredictedValues(m)
evaluateModelFit(hM=m, predY=preds)
preds.mean = apply(preds, FUN=mean, MARGIN=1)
nres = scale(y-preds.mean)
par(mfrow=c(1,2))
hist(nres, las = 1)
plot(preds.mean,nres, las = 1)
abline(a=0,b=0)
```

## 1B. Linear mixed model, single species, spatial (heirarcahical) study design

We now consider a population growing, where the species abundance is sampled from sites that are nested within plots. In such a case, two observations from the same plot are likely to be more similar to each other than two observations indifferent plots. We now introduce residuals for observations $y_i$ that are not independent of one another, and introduce into the statistical model a plot-level random effect.

As indicated in Ovaskainen & Abrego (Chapter 5), a standard way of implementing this dependency structure into the model is to add a plot-level random effect. To do so we use $a_p$ to denote the effect of plot $p$. The random effects are assumed to be normally distributed, so that $$ a_p \sim N(0,\sigma^2_p) $$, where $$ \sigma^2_p $$ is the variance in the plot-level effects. Right now, this suggests that in addition to the residual variance $\epsilon_i$, each data point also has residual variance associated with the sampling plot $a_p$. We can now extend the basic linear model into a mixed model:

$$ y_i = L_i + a_{p(i)} + \epsilon_i $$
$$ a_{p(i)} \sim N(0,\sigma^2_p) $$
$$ \epsilon_i \sim N(0,\sigma^2) $$
This is called a *mixed model* because it includes both fixed effects, i.e. the regression parameters included in the linear predictor $L_i$, as well as random effects, i.e. the effect of sampling date.

JDSM Chapter 5 text tells us another way of writing this equation (5.7 in the text), using the *multivariate normal distribution* for describing the distribution of response variables $y_i$ for all sampling units *i* - we denote by $\mathbf{y}$ the vector of length *n* (number of sampling units) with all of the values of $y_i$, we denote by $\mathbf{L}$ the vector of all linear predictors $L_i$, and by $\mathbf{\epsilon}$ the vector of all residuals $\epsilon_i$. We can then rewrite the equation as:

$$ \mathbf{y} \sim \mathbf{L} + \epsilon_i$$
$$ \epsilon_i \sim N(\mathbf{0},\mathbf{\Sigma}) $$

Where $N(\mathbf{\mu},\mathbf{\Sigma})$ stands for the multivariate normal distribution with mean $\mathbf{\mu}$ and variance-covariance matrix $\mathbf{\Sigma}$. We can also write out what this looks like for this example so far:

$$\begin{bmatrix} y_1\\
y_2\\
y_{...}\\
y_i
\end{bmatrix} = \begin{bmatrix}\beta_1 x_1\\
\beta_2 x_2\\
\end{bmatrix} \begin{bmatrix}\epsilon_1\\
\epsilon_2\\
\epsilon_{...}\\
\epsilon_i
\end{bmatrix}$$

In this equation above, the vector $\mathbf{\mu}$ is set to 0 because the expectation of each $\epsilon_i$ value is 0.

The diagonal elements of the variance-covariance matrix $\mathbf{\Sigma}$ model the variances, and thus are set to $\Sigma_{ii} = \sigma^2_p + \sigma^2$. The off-diagonal elements of the variance-covariance matrix $\mathbf{\Sigma}$ model the covariances, and here are set to $\Sigma_{ij} = \sigma^2_p$ if the sampling units *i* and *j* belong to the same plot, and $\Sigma_{ij} = 0$ if the sampling units *i* and *j* belong to different plots.

Before going back to the example shown above, I first visualize a variance-covariance matrix with $\sigma^2 = 4$ and $\sigma_p^2 = 0.8$. I then simulate draws from that variance-covariance matrix, for n=50 'sampling units' (observations) taken across 5 plots. Only samples collected from the same plot covary (to continue with this example using the logic from JDSM):

```{r}
samp <- rep(1:5,each=10)
sig <- 4
ap <- 0.8
m<-matrix(rep(NA,2500),ncol=50)
for(i in 1:50){
    for(j in 1:50){
       if(samp[i]==samp[j]){
           m[i,j] <- sig
           }
       else{
           m[i,j] <- 0
       }
    }
}
m <- as.matrix(m)
diag(m) <- ap + sig
```

For the example above, this variance-covariance matrix looks like this:

```{r echo=FALSE,results='asis',out.width="60%",warning=FALSE,message=FALSE}
kableExtra::kable_styling(knitr::kable(m,"html"),font_size = 7,position = "left",stripe_color = "gray!15",bootstrap_options = c("condensed"))

heatmap(m,Rowv=NA,Colv=NA,revC=TRUE,col=colorRampPalette(RColorBrewer::brewer.pal(8, "Blues"))(25))
legend(x="bottomright", legend=c("0", "covar", "var"), bty="n", cex=0.7, fill=colorRampPalette(RColorBrewer::brewer.pal(8, "Blues"))(3))
```

This example represents 50 total sites / sampling units (i = 1:50), and some sites / sampling units were sampled from shared plots (p = 1:5). As we can see from the image, data points $y_1$:$y_{10}$ are from sites 1-10 sampled in Plot 1. Data points $y_{11}$:$y_{20}$ are from sites 11-20 sampled in Plot 2, data points $y_{21}$:$y_{30}$ are from sites 21-30 sampled in Plot 3, data points $y_{31}$:$y_{40}$ are from sites 31-40 sampled in Plot 4, and data points $y_{41}$:$y_{50}$ are from sites 41-50 sampled in Plot 5. In the example pictured, each site has the same sample variance $\sigma^2 = 4$ and also each sampling day has the same within-day covariance $\sigma_t^2 = 0.8$. We now look at how to draw residuals from the multivariate normal distribution using the command `MASS::mvrnorm`:

```{r}
# 2 heirarchical groups: mean [0 2], variance [10 2], covariance [3]. Draw for 10 points from each group.
Sigma <- matrix(c(10,3,3,2),2,2)
Sigma
blah <- MASS::mvrnorm(n = 100, c(0,2), Sigma)
var(blah)
```

Now we can draw the residuals $\epsilon_i$ for our hypothetical 50 sites sampled across 5 plots this way:

```{r}
# 5 heirarchical groups: mean [0 0 0 0 0 0 0 0 0 0]; variance: [4.8 4.8 4.8 4.8 4.8 4.8 4.8 4.8 4.8 4.8 4.8]; covariance: see matrix above. Draw for 1 point from each group.
resid <-  MASS::mvrnorm(1, rep(0,50), m)
```

Putting it all together - we now attempt to sample data points that represent population size `n` of a single species sampled at `i= 50` sampling units, each of which has a distinct value for an environmental covariate $x_i$. Each of the sampling units was sampled in one of 5 plots (as above), meaning that we need to consider not only variance but also covariance between sampling unit values sampled in the same plot. Our model becomes:

$$ y_i = L_i + a_{p(i)} + \epsilon_i $$
$$ L_i = \sum^{n_c}_{k=1} x_{ik} \beta_k $$
$$ a_{p(i)} \sim N(0,\sigma^2_p) $$
$$ \epsilon_i \sim N(0,\sigma^2) $$

For this example:

+ $L_i$ - I use environmental values $e \sim N(0,1)$ for $i = 50$ sites / sampling units, $\beta_1 = 450$ and $x_{ik} = 1$, $\beta_2 = 1.23$

+ $\sigma_{p}^2$ = [0.25 0.35 0.23 0.05 0.1] for `p = 1:5`

+ $\sigma^2 = 0.7$

```{r,out.width="50%"}
n <- 50
x <- rnorm(n)
x1 <- rep(1,n)
x2 <- x
beta1 <- 450
beta2 <- 1.23
L <- beta1*x1 + beta2*x2

## Method 1 of drawing residual values
n.plot <- rep(1:5,each=10)
sigma.plot <- c(0.25,0.35,0.23,0.05,0.1)
ap <- rep(NA,n)
for(i in 1:n){
  ap[i] <- rnorm(1,0,sd = sigma.plot[n.plot[i]])
}
y <- L + ap + rnorm(n, sd=0.7)
plot(x,L,main="Impact of environment x on population size Y at site i",ylab="yi")
plot(x,y,main="Impact of environment x on population size Y at site i",ylab="yi")
# colored by day
cols = rainbow(5)
plot(x, y, col = cols[n.plot], las = 1, main="Impact of environment x on population size Y at site i",ylab="yi")
for (p in 1:5){
abline(beta1+ap[p], beta2, col = cols[p]) }
```

This data is analyzed via mixed models as follows:

```{r}
n.plot <- as.factor(n.plot)
# random intercepts only
mod <- lme4::lmer(y ~ x + (1 | n.plot))
# random intercepts and slopes
#mod <- lme4::lmer(y ~ x + (1 + x | n.plot))
summary(mod)
mixedup::extract_random_effects(mod)
lme4::ranef(mod)$n.plot

# Complicated.
var.d <- crossprod(getME(mod,"Lambdat"))
Zt <- getME(mod,"Zt")
vr <- sigma(mod)^2
var.b <- vr*(t(Zt) %*% var.d %*% Zt)
sI <- vr * Diagonal(length(x))
var.y <- var.b + sI
m <- as.matrix(var.y)

kableExtra::kable_styling(knitr::kable(m,"html"),font_size = 7,position = "left",stripe_color = "gray!15",bootstrap_options = c("condensed"))

heatmap(m,Rowv=NA,Colv=NA,revC=TRUE,col=colorRampPalette(RColorBrewer::brewer.pal(8, "Blues"))(25))
legend(x="bottomright", legend=c("0", "covar", "var"), bty="n", cex=0.7, fill=colorRampPalette(RColorBrewer::brewer.pal(8, "Blues"))(3))

```

How to interpret this? What are the estimates of the effects of site / sampling values collected from the same plot? We can see the estimates are poor. These are the estimates of the variance for the plot effect, telling us how much *y* varies among sampling units sampled within the same plot - the solvers are not designed to estimate these, but instead to consider them for the fixed effect estimates. Fin.

This data is analyzed via HMSC as follows:

```{r out.width="70%"}
plot.id = as.factor(n.plot)
sample.id = as.factor(1:n)
XData = data.frame(x = x)
Y = as.matrix(y)
studyDesign = data.frame(sample = sample.id, plot = plot.id)
rL = HmscRandomLevel(units = studyDesign$plot)
m2 = Hmsc(Y = Y, XData = XData, XFormula = ~x, studyDesign = studyDesign, ranLevels = list('plot' = rL))

thin = 5
samples = 5000
transient = 1000*thin
m2 = sampleMcmc(m2, thin = thin, samples = samples, transient = transient, nChains = nChains, verbose = verbose, initPar="fixed effects")

# Interpret results
m2.post = Hmsc::convertToCodaObject(m2)
m2.df <- as.data.frame(rbind(m2.post$Beta[[1]],m2.post$Beta[[2]]))
bayesplot::mcmc_areas(m2.df)
summary(m2.post$Beta)
plot(m2.post$Beta)
preds = computePredictedValues(m2)
evaluateModelFit(hM=m2, predY=preds)
preds.mean = apply(preds, FUN=mean, MARGIN=1)
nres = scale(y-preds.mean)
par(mfrow=c(1,2))
hist(nres, las = 1)
plot(preds.mean,nres, las = 1)
abline(a=0,b=0)
```

We can see that by properly taking the random effects of plot into account, using a mixed model, we can now correctly estimate the $\alpha = \beta_1$ and $\beta = \beta_2$ coefficients.

We cannot look more carefully at the HMSC estimates for the random effects. This is complicated. We recall that HMSC uses latent variables. I make some very fast code to extract these:

```{r out.width="70%"}
etaPost=getPostEstimate(m2, "Eta")
lambdaPost=getPostEstimate(m2, "Lambda")
biPlot(m2, etaPost = etaPost, lambdaPost = lambdaPost, factors = c(1,1), "x")
```
I will leave the latent variable code for another time, but here are also we end. From Abrego & Ovaskainen, "the model does not have the possibility to estimate the actual random effect for the plot".

## 2. Spatial autocorrelation

Spatial structure may not only follow a plot structure, but instead it may be that residuals are correlated in a way that depends on the distance (euclidean distance, in xy or latitude-longitude) between sites i and j. HMSC models the variance-covariance matrix as:

$$\Sigma_{ij} = f(d_{ij}) + \delta_{ij} \sigma^2$$

where $d_{ij}$ is the distance between sampling units *i* and *j*, and $f(d)$ is the spatial covariance function. $\delta_{ij} = 0$ for $i=j$ and $\delta_{ij} = 0$ for $i \neq j$.

HMSC implements 1 specific spatial covariance function:

$$ f(d) = \sigma_S^2 e^{-d_{ij} / \alpha} $$
Here, $\sigma_S^2$ is the spatial variance and $\alpha$ is the characteristic spatial scale of the spatial autocorrelation.

We can look at sites with spatial autocorrelation in this way:

```{r warning=FALSE}
n = 100
beta1 = 0
beta2 = 1
sigma = 1
sigma.spatial = 2
alpha.spatial = 0.5
x = rnorm(n)
L = beta1 + beta2*x
xycoords = matrix(runif(2*n), ncol = 2)
Sigma = sigma.spatial^2*
  exp(-as.matrix(dist(xycoords))/alpha.spatial)
a = mvrnorm(mu=rep(0,n), Sigma = Sigma)
y = L + a + rnorm(n, sd = sigma)

# plot x variable - no spatial structure
pal <- colorRampPalette(c("white", "blue"))
plot(xycoords,col="grey90", fill=TRUE, warnings=F, xlab="X coord",ylab="Y coord")
options(warn=0)
points(xycoords[,1], xycoords[,2],pch = 21,bg = pal(10)[as.numeric(cut(x,breaks = 10))],col="black")

legend_image <- as.raster(matrix(rev(pal(10)), ncol=1))
plot(c(0,2),c(0,1),type = 'n', axes = F,xlab = '', ylab = '', main = 'E value')
text(x=1.5, y = seq(0,1,l=5), labels = seq(0,1,l=5))
rasterImage(legend_image, 0, 0, 1, 1) ## set new for ov

# plot y, spatial structure
pal <- colorRampPalette(c("white", "orange"))
plot(xycoords,col="grey90", fill=TRUE, warnings=F, xlab="X coord",ylab="Y coord")
options(warn=0)
points(xycoords[,1], xycoords[,2],pch = 21,bg = pal(10)[as.numeric(cut(y,breaks = 10))],col="black")

legend_image <- as.raster(matrix(rev(pal(10)), ncol=1))
plot(c(0,2),c(0,1),type = 'n', axes = F,xlab = '', ylab = '', main = 'y (abundance)')
text(x=1.5, y = seq(0,1,l=6), labels = seq(0,15,l=6))
rasterImage(legend_image, 0, 0, 1, 1) ## set new for overplot w/ next plot

plot(apply(xycoords,1,dist),y)

```

And we can consider this spatial structure in an HMSC model to estimate the intercept and beta parameters, as well as the spatial parameters:

```{r}
sample.id = as.factor(1:n)
studyDesign = data.frame(sample = sample.id)
rownames(xycoords) = sample.id
rL = HmscRandomLevel(sData = xycoords)
XData = data.frame(x)
Y = as.matrix(y)
m = Hmsc(Y = Y, XData = XData, XFormula = ~x,
studyDesign = studyDesign, ranLevels = list("sample" = rL))

# MCMC parameters
nChains = 2
thin = 5
samples = 2000
transient = 500*thin
verbose = 500*thin
# Fit model
m = sampleMcmc(m, thin = thin, samples = samples, transient = transient, nChains = nChains, verbose = verbose)
```

```{r}
mpost = convertToCodaObject(m)
plot(mpost$Alpha[[1]])
plot(mpost$Beta)
```

Another part that needs explanation is the Variance Partioning (Varpart). It is used in the Hmsc to explain how much the variance in a covariate explains the covariate in the depended variable. As the covariate are as well measured empirical data they have a variance (e.g. temperature changing depending on the measurement). The equation for a single covariate is given by: $$\beta^2_kVar[x_{.k}]/Var[L]$$. 
k determines which covarite is used, the . stands for the full vector off all measurements from this covariate. We can show this effect with a simple example as above, in which we predict a variable with a single covariate
```{r}
n = 100
beta1 = 450
beta2 = 1
x = rnorm(n)
L = beta1 + beta2*x
"Variation of L explained by variation of covariate x:";beta^2*var(x)/var(L)
```
As we see here the variance in covariate x predict all the variance in the linear predictor L, which makes sense as all the only variable with variance in this equation is x. So that all variance here can come only from x.

Lets see what happens when we add a second variable:
```{r}
set.seed(1)
n = 100
beta1 = 450
beta2 = 1
beta3 = 1
x = rnorm(n,sd=1)
x2 = rnorm(n,sd=1)
L = beta1 + beta2*x + beta3*x2
"Variation of L explained by variation of covariate x:";beta^2*var(x)/var(L)
```
Now the variance in the first covariate is 47%, so explains almost half of the variation in L, which makes sens as both x and x2 are drawn from the sam distribution and have the same beta. But then why is it 47% and not 50%?
```{r}
"Variation of covariate x:";var(x)
"Variation of covariate x2:";var(x2)
```

While they are both drawn from the same distrubtion x2 has a slightly greate variance, which is expectd as we have only 100 draws from the distribution the variance is not a perfect representation of the original distribution (with a standard deviation = 1). This results shows that an increased variance in one of the covariate, results in a greater variance in L. So the reate variance in x2 results in a greater explanation of the variance in L.
```{r}
"Variation of L explained by variation of covariate x2:";beta^2*var(x2)/var(L)
```